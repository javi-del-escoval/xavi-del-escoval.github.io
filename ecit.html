<!DOCTYPE html>
<html>
	<head>
		<meta charset="UTF-8">
		<title>Xavier Del Escoval | Proyectos ECIT</title>
		<link rel="stylesheet" href="styles.css">
		<script>
			fetch('https://api.github.com/repos/javi-del-escoval/javi-del-escoval.github.io/contents/Scraper/Installers')
			.then(res => res.json())
			.then(files => {
				const container = document.getElementById('scraper-installers');
				files.forEach(file => {
					if (file.type === 'file') {
						const a = document.createElement('a');
						a.href = file.download_url;
						a.download = file.name;
						a.textContent = file.name;
						container.appendChild(a);
						container.appendChild(document.createElement('br'));
					}
				});
			});
		</script>
	</head>
	<body>
		<h1>Proyectos ECIT</h1>
		<div id="projects-links">
			<a href="#scraper">Web Scraper</a>
			<a href="#webpage-generator">Generador HTML para WordPress</a>			
		</div>
		<section id="projects">
			<div id="scraper">
				<h2>Web Scraper</h2>
				<h3>Descarga e instalación</h3>
				Selecciona la ultima version disponible, ejecuta y sigue las instrucciones del instalador
				(Por defecto el programa se instala en Documentos)
				<a href="/Scraper/Changelog.md">que cambio en la ultima version?</a>
				<div class="separator"></div>
				<div id="scraper-installers"></div>
				<div class="separator"></div>
				<h3>Uso</h3>
				<h4>Inicio</h4>
				Aquí se da la instrucción al programa de realizar scraping, todo proceso de scraping genera un archivo Excel con los resultados (ver Data).<br>Cada vez que se realiza un scraping ya sea general o individual los resultados sobrescriben el archivo Excel.
				<img src="Scraper/readme/inicio.png" />
				Con La configuración por defecto un scraping general toma aproximadamente 12 minutos<br>
				Desglose por plataforma:<br>
				<ul>
					<li>Mercado Publico: 13 segundos</li>
					<li>BID: 9 segundos</li>
					<li>ANID: 3 segundos</li>
					<li>SERCOTEC: 9 minutos 8 segundos</li>
					<li>CORFO: 48 segundos</li>
					<li>CODESSER: 50 segundos</li>
				</ul>
				<div class="separator"></div>
				<h4>Data</h4>
				En Data puedes editar el nombre del archivo en donde se guardarán los resultados, este archivo se escribe de manera relativa a donde está el instalado el programa, si el archivo no existe se creará. Si desea que sus archivos se guarden en una carpeta por separado la carpeta debe existir antes de iniciar un proceso de scraping.<br>
				E.g.1:<br>
				<img src="Scraper/readme/data.png" />
				Web Scraper 0.1.5/<br>
				├─ _internal/<br>
				├─ config.json<br>
				├─ <span style="color:blue">Scraping.xlsx*</span><br>
				├─ unins000.dat<br>
				├─ unins000.exe<br>
				└─ Web Scraper.exe<br>
				E.g.2:<br>
				<img src="Scraper/readme/data1.png" /><br>
				Web Scraper 0.1.5/<br>
				└─ <span style="color: red;">data/ <-- No existe</span><br>
				&emsp;└─ <span style="color: red;">Scraping.xlsx*</span><br>
				├─ _internal/<br>
				├─ config.json<br>
				├─ unins000.dat<br>
				├─ unins000.exe<br>
				└─ Web Scraper.exe
				<div class="separator"></div>
				<h4>Keywords</h4>
				<img src="Scraper/readme/keywords.png" /><br>
				Aquí se añade la información para filtrar los resultados, tanto las keywords como las palabras de exclusión deben estar separadas, dejando una por línea. Tambien el ticket de Mercado Publico para acceso a su <a href="https://api.mercadopublico.cl/modules/api.aspx">API</a><br>
			</div>
			<div class="separator"></div>
			<div id="webpage-generator">
				<h3>Generadores de HTML</h3>
				<a href="/custom-form" download="generate-form-html.py">Generate Form</a><br>
				<a href="/custom-form" download="Básicos.txt">Módulos Básicos</a><br>
				<a href="/custom-form" download="Avanzados.txt">Módulos Avanzados</a><br>
				<a href="/custom-form" download="form.html">Form.html</a><br>
				<a href="/custom-form" download="generate-list-html.py">Generate List</a><br>
				<a href="/custom-form" download="list.html">List.html</a><br>
				<a href="/custom-form" download="modulos.txt">Módulos</a><br>
			</div>
	</body>
</html>

